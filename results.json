[
    {
        "model_name":"Llama-2-13b-hf",
        "model_url":"https:\/\/huggingface.co\/meta-llama\/Llama-2-13b-hf",
        "model_family":"llama",
        "model_type":"CLM",
        "year_published": 2023,
        "num_params":13e9,
        "num_tokens": 2e12,
        "size_pretraining_GB":null,
        "source":"https://huggingface.co/meta-llama/Llama-2-13b-hf",
        "accuracy":{
            "mean":0.6691674212,
            "sem":0.0103437271
        }
    },
    {
        "model_name":"Llama-2-7b-hf",
        "model_url":"https:\/\/huggingface.co\/meta-llama\/Llama-2-7b-hf",
        "model_family":"llama",
        "model_type":"CLM",
        "year_published": 2023,
        "num_params":7e9,
        "num_tokens": 2e12,
        "size_pretraining_GB":null,
        "source":"https://huggingface.co/meta-llama/Llama-2-7b-hf", 
        "accuracy":{
            "mean":0.6239813737,
            "sem":0.0130318022
        }
    },
    {
        "model_name":"Mistral-7B-v0.1",
        "model_url":"https:\/\/huggingface.co\/mistralai\/Mistral-7B-v0.1",
        "model_family":"mistral",
        "model_type":"CLM",
        "year_published": 2023,
        "num_params":7e9,
        "num_tokens":null,
        "size_pretraining_GB":null,
        "source":"https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/8",
        "accuracy":{
            "mean":0.6537317294,
            "sem":0.0111468343
        }
    },
    {
        "model_name":"bert-base-cased",
        "model_url":"https:\/\/huggingface.co\/bert-base-cased",
        "model_family":"bert",
        "model_type":"MLM",
        "year_published": 2018,
        "num_params":109e6,
        "num_tokens":3.3e9,
        "size_pretraining_GB":null,
        "source":"https://huggingface.co/blog/bert-101",
        "accuracy":{
            "mean":0.1839348079,
            "sem":0.0036593149
        }
    },
    {
        "model_name":"bert-large-cased",
        "model_url":"https:\/\/huggingface.co\/bert-large-cased",
        "model_family":"bert",
        "model_type":"MLM",
        "year_published": 2018,
        "num_params":335e6,
        "num_tokens":3.3e9,
        "size_pretraining_GB":null,
        "source":"https://huggingface.co/blog/bert-101",
        "accuracy":{
            "mean":0.199111801,
            "sem":0.0048284658
        }
    },
    {
        "model_name":"gemma-2b",
        "model_url":"https:\/\/huggingface.co\/google\/gemma-2b",
        "model_family":"gemma",
        "model_type":"CLM",
        "year_published": 2024,
        "num_params":2e9,
        "num_tokens":2e12,
        "size_pretraining_GB":null,
        "source":"https://cloud.google.com/blog/products/ai-machine-learning/performance-deepdive-of-gemma-on-google-cloud",
        "accuracy":{
            "mean":0.5153710171,
            "sem":0.0102554649
        }
    },
    {
        "model_name":"gemma-7b",
        "model_url":"https:\/\/huggingface.co\/google\/gemma-7b",
        "model_family":"gemma",
        "model_type":"CLM",
        "year_published": 2024,
        "num_params":7e9,
        "num_tokens":6e12,
        "size_pretraining_GB":null,
        "source":"https://cloud.google.com/blog/products/ai-machine-learning/performance-deepdive-of-gemma-on-google-cloud",
        "accuracy":{
            "mean":0.6372181262,
            "sem":0.0131199491
        }
    },
    {
        "model_name":"gpt2",
        "model_url":"https:\/\/huggingface.co\/gpt2",
        "model_family":"gpt2",
        "model_type":"CLM",
        "year_published": 2019,
        "num_params":137e6,
        "num_tokens":null,
        "size_pretraining_GB":40.0,
        "source":"https://openai.com/index/better-language-models/", 
        "accuracy":{
            "mean":0.1349113957,
            "sem":0.0075913133
        }
    },
    {
        "model_name":"gpt2-large",
        "model_url":"https:\/\/huggingface.co\/gpt2-large",
        "model_family":"gpt2",
        "model_type":"CLM",
        "year_published": 2019,
        "num_params":812e6,
        "num_tokens":null,
        "size_pretraining_GB":40.0,
        "source":"https://openai.com/index/better-language-models/", 
        "accuracy":{
            "mean":0.2223946881,
            "sem":0.0060671766
        }
    },
    {
        "model_name":"gpt2-medium",
        "model_url":"https:\/\/huggingface.co\/gpt2-medium",
        "model_family":"gpt2",
        "model_type":"CLM",
        "year_published": 2019,
        "num_params":355e6,
        "num_tokens": null,
        "size_pretraining_GB":40.0,
        "source":"https://openai.com/index/better-language-models/", 
        "accuracy":{
            "mean":0.1901866943,
            "sem":0.0083842388
        }
    },
    {
        "model_name":"gpt2-xl",
        "model_url":"https:\/\/huggingface.co\/gpt2-xl",
        "model_family":"gpt2",
        "model_type":"CLM",
        "year_published": 2019,
        "num_params":1.600e9,
        "num_tokens":null,
        "size_pretraining_GB":40.0,
        "source":"https://openai.com/index/better-language-models/", 
        "accuracy":{
            "mean":0.2624067607,
            "sem":0.0068037989
        }
    },
    {
        "model_name":"opt-1.3b",
        "model_url":"https:\/\/huggingface.co\/facebook\/opt-1.3b",
        "model_family":"opt",
        "model_type":"CLM",
        "year_published": 2022,
        "num_params":1300e6,
        "num_tokens":180e9,
        "size_pretraining_GB":800,
        "source":"https://huggingface.co/facebook/opt-1.3b", 
        "accuracy":{
            "mean":0.3146207908,
            "sem":0.0084048343
        }
    },
    {
        "model_name":"opt-125m",
        "model_url":"https:\/\/huggingface.co\/facebook\/opt-125m",
        "model_family":"opt",
        "model_type":"CLM",
        "year_published": 2022,
        "num_params":125000000.0,
        "num_tokens":180e9,
        "size_pretraining_GB":800.0,
        "source":"https://huggingface.co/facebook/opt-125m", 
        "accuracy":{
            "mean":0.1637563058,
            "sem":0.0049175449
        }
    },
    {
        "model_name":"opt-13b",
        "model_url":"https:\/\/huggingface.co\/facebook\/opt-13b",
        "model_family":"opt",
        "model_type":"CLM",
        "year_published": 2022,
        "num_params":13e9,
        "num_tokens":180e9,
        "size_pretraining_GB":800.0,
        "source":"https://huggingface.co/facebook/opt-13b", 
        "accuracy":{
            "mean":0.4542318803,
            "sem":0.0078447074
        }
    },
    {
        "model_name":"opt-2.7b",
        "model_url":"https:\/\/huggingface.co\/facebook\/opt-2.7b",
        "model_family":"opt",
        "model_type":"CLM",
        "year_published": 2022,
        "num_params":2700e6,
        "num_tokens":180e9,
        "size_pretraining_GB":800.0,
        "source":"https://huggingface.co/facebook/opt-2.7b", 
        "accuracy":{
            "mean":0.3725693097,
            "sem":0.0090487054
        }
    },
    {
        "model_name":"opt-30b",
        "model_url":"https:\/\/huggingface.co\/facebook\/opt-30b",
        "model_family":"opt",
        "model_type":"CLM",
        "year_published": 2022,
        "num_params":30e9,
        "num_tokens":180e9,
        "size_pretraining_GB":800.0,
        "source":"https://huggingface.co/facebook/opt-30b", 
        "accuracy":{
            "mean":0.4790669599,
            "sem":0.005280842
        }
    },
    {
        "model_name":"opt-350m",
        "model_url":"https:\/\/huggingface.co\/facebook\/opt-350m",
        "model_family":"opt",
        "model_type":"CLM",
        "year_published": 2022,
        "num_params":350e6,
        "num_tokens":180e9,
        "size_pretraining_GB":800.0,
        "source":"https://huggingface.co/facebook/opt-350m", 
        "accuracy":{
            "mean":0.1955762515,
            "sem":0.0060867551
        }
    },
    {
        "model_name":"opt-6.7b",
        "model_url":"https:\/\/huggingface.co\/facebook\/opt-6.7b",
        "model_family":"opt",
        "model_type":"CLM",
        "year_published": 2022,
        "num_params":6700e6,
        "num_tokens":180e9,
        "size_pretraining_GB":800.0,
        "source":"https://huggingface.co/facebook/opt-6.7b", 
        "accuracy":{
            "mean":0.43780451,
            "sem":0.0111271373
        }
    },
    {
        "model_name":"roberta-base",
        "model_url":"https:\/\/huggingface.co\/roberta-base",
        "model_family":"roberta",
        "model_type":"MLM",
        "year_published": 2019,
        "num_params":125e6,
        "num_tokens":null,
        "size_pretraining_GB":160.0,
        "source":"https://arxiv.org/pdf/1907.11692", 
        "accuracy":{
            "mean":0.1644892856,
            "sem":0.007326373
        }
    },
    {
        "model_name":"roberta-large",
        "model_url":"https:\/\/huggingface.co\/roberta-large",
        "model_family":"roberta",
        "model_type":"MLM",
        "year_published": 2019,
        "num_params":355e6,
        "num_tokens":null,
        "size_pretraining_GB":160.0,
        "source":"https://arxiv.org/pdf/1907.11692", 
        "accuracy":{
            "mean":0.2151511232,
            "sem":0.008007598
        }
    },
    {
        "model_name":"xlm-roberta-base",
        "model_url":"https:\/\/huggingface.co\/xlm-roberta-base",
        "model_family":"xlm-roberta",
        "model_type":"MLM",
        "year_published": 2020,
        "num_params":279e6,
        "num_tokens":null,
        "size_pretraining_GB":2500.0,
        "source":"https://huggingface.co/FacebookAI/xlm-roberta-base",
        "accuracy":{
            "mean":0.1138705644,
            "sem":0.0021609907
        }
    },
    {
        "model_name":"xlm-roberta-large",
        "model_url":"https:\/\/huggingface.co\/xlm-roberta-large",
        "model_family":"xlm-roberta",
        "model_type":"MLM",
        "year_published": 2020,
        "num_params":561e6,
        "num_tokens":null,
        "size_pretraining_GB":2500.0,
        "source":"https://huggingface.co/FacebookAI/xlm-roberta-large",
        "accuracy":{
            "mean":0.1433191049,
            "sem":0.0032859154
        }
    },
    {
        "model_name":"Random Baseline",
        "model_url":null,
        "model_family":"baseline",
        "model_type":null,
        "num_params":null,
        "num_tokens":null,
        "size_pretraining_GB": null,
        "source":null,
        "accuracy":{
            "mean":0.0468244729
        }
    },
    {
        "model_name": "Meta-Llama-3-8B",
        "model_url": "https://huggingface.co/meta-llama/Meta-Llama-3-8B",
        "model_family": "llama-3",
        "model_type": "CLM",
        "year_published": 2024,
        "num_params": 8e9,
        "num_tokens": 15e12,
        "size_pretraining_GB":null,
        "source":"https://huggingface.co/meta-llama/Meta-Llama-3-8B", 
        "accuracy": {
          "mean": 0.68594,
          "sem": 0.012737
        }
    },
    {
        "model_name": "Meta-Llama-3-8B-Instruct",
        "model_url": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct",
        "model_family": "llama-3",
        "model_type": "CLM-IT",
        "year_published": 2024,
        "num_params": 8e9,
        "num_tokens": 15e12,
        "size_pretraining_GB":null,
        "source":"https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct", 
        "accuracy": {
            "mean": 0.64084,
            "sem":  0.014853
         }
    },
    {
      "model_name": "microsoft/phi-4",
      "model_url": "https://huggingface.co/microsoft/phi-4",
      "model_type": "CLM",
      "model_family": "phi-4",
      "num_params": 14e9,
      "num_tokens": 9.8e12,
      "size_pretraining_GB": null,
      "source": null,
      "accuracy": {
        "mean": 0.6045138888888889,
        "sem": 0.009636589643318007
      }
    },
    {
      "model_name": "state-spaces/mamba-130m-hf",
      "model_url": "https://huggingface.co/state-spaces/mamba-130m-hf",
      "model_type": "CLM",
      "model_family": "mamba",
      "num_params": 130e6,
      "num_tokens": 300e9,
      "size_pretraining_GB": null,
      "source": "https://github.com/state-spaces/mamba",
      "accuracy": {
        "mean": 0.1892812486526107,
        "sem": 0.0060607385910181584
      }
    },
    {
      "model_name": "state-spaces/mamba-1.4b-hf",
      "model_url": "https://huggingface.co/state-spaces/mamba-1.4b-hf",
      "model_type": "CLM",
      "model_family": "mamba",
      "num_params": 1.4e9,
      "num_tokens": 300e9,
      "size_pretraining_GB": null,
      "source": "https://github.com/state-spaces/mamba",
      "accuracy": {
        "mean": 0.40464795412408916,
        "sem": 0.0071006142774747046
      }
    },
    {
      "model_name": "state-spaces/mamba-2.8b-hf",
      "model_url": "https://huggingface.co/state-spaces/mamba-2.8b-hf",
      "model_type": "CLM",
      "model_family": "mamba",
      "num_params": 2.8e9,
      "num_tokens": 300e9,
      "size_pretraining_GB": null,
      "source": "https://github.com/state-spaces/mamba",
      "accuracy": {
        "mean": 0.46164791100763164,
        "sem": 0.009607039522409648
      }
    },
    {
      "model_name": "state-spaces/mamba-790m-hf",
      "model_url": "https://huggingface.co/state-spaces/mamba-790m-hf",
      "model_type": "CLM",
      "model_family": "mamba",
      "num_params": 790e6,
      "num_tokens": 300e9,
      "size_pretraining_GB": null,
      "source": "https://github.com/state-spaces/mamba",
      "accuracy": {
        "mean": 0.35092484801448715,
        "sem": 0.007836408746623613
      }
    },
    {
      "model_name": "state-spaces/mamba-370m-hf",
      "model_url": "https://huggingface.co/state-spaces/mamba-370m-hf",
      "model_type": "CLM",
      "model_family": "mamba",
      "num_params": 370e6,
      "num_tokens": 300e9,
      "size_pretraining_GB": null,
      "source": "https://github.com/state-spaces/mamba",
      "accuracy": {
        "mean": 0.2773681714310352,
        "sem": 0.008850224016471191
      }
    },
    {
      "model_name": "HuggingFaceTB/SmolLM-360M",
      "model_url": "https://huggingface.co/HuggingFaceTB/SmolLM-360M",
      "model_type": "CLM",
      "model_family": "SmolLM",
      "num_params": 360e6,
      "num_tokens": 600e9,
      "size_pretraining_GB": null,
      "source": "https://huggingface.co/HuggingFaceTB/SmolLM-360M",
      "accuracy": {
        "mean": 0.2619324796274738,
        "sem": 0.008990479300739953
      }
    },
    {
      "model_name": "HuggingFaceTB/SmolLM-135M",
      "model_url": "https://huggingface.co/HuggingFaceTB/SmolLM-135M",
      "model_type": "CLM",
      "model_family": "SmolLM",
      "num_params": 135e6,
      "num_tokens": 600e9,
      "size_pretraining_GB": null,
      "source": "https://huggingface.co/HuggingFaceTB/SmolLM-135M",
      "accuracy": {
        "mean": 0.193722243780451,
        "sem": 0.01374644360552194
      }
    },
    {
      "model_name": "HuggingFaceTB/SmolLM-1.7B",
      "model_url": "https://huggingface.co/HuggingFaceTB/SmolLM-1.7B",
      "model_type": "CLM",
      "model_family": "SmolLM",
      "num_params": 1.7e9,
      "num_tokens": 1e12,
      "size_pretraining_GB": null,
      "source": "https://huggingface.co/HuggingFaceTB/SmolLM-1.7B",
      "accuracy": {
        "mean": 0.3551502608545682,
        "sem": 0.011106066327479017
      }
    },
    {
      "model_name": "HuggingFaceTB/SmolLM2-360M",
      "model_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-360M",
      "model_type": "CLM",
      "model_family": "SmolLM2",
      "num_params": 360e6,
      "num_tokens": 4e12,
      "size_pretraining_GB": null,
      "source": "https://huggingface.co/HuggingFaceTB/SmolLM2-360M",
      "accuracy": {
        "mean": 0.2772388220583797,
        "sem": 0.009235078201486894
      }
    },
    {
      "model_name": "HuggingFaceTB/SmolLM2-135M",
      "model_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-135M",
      "model_type": "CLM",
      "model_family": "SmolLM2",
      "num_params": 135e6,
      "num_tokens": 2e12,
      "size_pretraining_GB": null,
      "source": "https://huggingface.co/HuggingFaceTB/SmolLM2-135M",
      "accuracy": {
        "mean": 0.1986375199413616,
        "sem": 0.011577391093948652
      }
    },
    {
      "model_name": "HuggingFaceTB/SmolLM2-1.7B",
      "model_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B",
      "model_type": "CLM",
      "model_family": "SmolLM2",
      "num_params": 1.7e9,
      "num_tokens": 11e12,
      "size_pretraining_GB": null,
      "source": "https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B",
      "accuracy": {
        "mean": 0.4085715517613073,
        "sem": 0.016498229515710984
      }
    }
]
